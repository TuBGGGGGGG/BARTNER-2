{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybuilddir.txt\n",
      "pybuilddir.txt\n",
      "/usr/share/zoneinfo/UTC\n",
      "/usr/lib/ssl/certs/ca-certificates.crt\n",
      "[SET SEED]:  1688\n",
      "max_len_a:1.6, max_len:10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from data.pipe import BartNERPipe,Bart_RE_NER_Pipe\n",
    "from model.bart import BartSeq2SeqModel\n",
    "import fitlog\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from fastNLP import Trainer\n",
    "from model.metrics import Seq2SeqSpanMetric,Seq2SeqREMetric\n",
    "from model.losses import Seq2SeqLoss\n",
    "from torch import optim\n",
    "from fastNLP import BucketSampler, GradientClipCallback, cache_results\n",
    "\n",
    "from model.callbacks import WarmupCallback\n",
    "from fastNLP.core.sampler import SortedSampler\n",
    "from model.generater import SequenceGeneratorModel\n",
    "from fastNLP.core.sampler import  ConstTokenNumSampler\n",
    "from model.callbacks import FitlogCallback\n",
    "\n",
    "fitlog.debug()\n",
    "fitlog.set_log_dir('logs')\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_name', default='re_ner_ace05', type=str)\n",
    "\n",
    "def set_seed(seed=1996):\n",
    "    print(\"[SET SEED]: \",seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "args= parser.parse_args([])\n",
    "dataset_name = args.dataset_name\n",
    "args.length_penalty = 1\n",
    "args.save_model = 1\n",
    "\n",
    "# word: 生成word的start; bpe: 生成所有的bpe; span: 每一段按照start end生成; span_bpe: 每一段都是start的所有bpe，end的所有bpe\n",
    "args.target_type = 'word'\n",
    "args.bart_name = '/disk1/wxl/Desktop/DeepKE/example/ner/huggingface/bart-large'\n",
    "args.schedule = 'linear'\n",
    "args.decoder_type = 'avg_feature'\n",
    "args.n_epochs = 30\n",
    "args.num_beams = 1\n",
    "args.batch_size = 16\n",
    "args.use_encoder_mlp = 1\n",
    "args.lr = 1e-5\n",
    "args.warmup_ratio = 0.01\n",
    "eval_start_epoch = 1\n",
    "\n",
    "# the following hyper-parameters are for target_type=word\n",
    "if dataset_name == 'conll2003':  # three runs get 93.18/93.18/93.36 F1\n",
    "    max_len, max_len_a = 10, 0.6\n",
    "elif dataset_name == 'en-ontonotes':  # three runs get 90.46/90.4/90/52 F1\n",
    "    max_len, max_len_a = 10, 0.8\n",
    "elif dataset_name == 'CADEC':\n",
    "    max_len, max_len_a = 10, 1.6\n",
    "    args.num_beams = 4\n",
    "    args.lr = 2e-5\n",
    "    args.n_epochs = 30\n",
    "    eval_start_epoch=10\n",
    "elif dataset_name == 'Share_2013':\n",
    "    max_len, max_len_a = 10, 0.6\n",
    "    args.use_encoder_mlp = 0\n",
    "    args.num_beams = 4\n",
    "    args.lr = 2e-5\n",
    "    eval_start_epoch = 5\n",
    "elif dataset_name == 'Share_2014':\n",
    "    max_len, max_len_a = 10, 0.6\n",
    "    args.num_beams = 4\n",
    "    eval_start_epoch = 5\n",
    "    args.n_epochs = 30\n",
    "elif dataset_name == 'genia':  # three runs: 79.29/79.13/78.75\n",
    "    max_len, max_len_a = 10, 0.5\n",
    "    args.target_type = 'span'\n",
    "    args.lr = 2e-5\n",
    "    args.warmup_ratio = 0.01\n",
    "elif dataset_name == 'en_ace04':  # four runs: 86.84/86.33/87/87.17\n",
    "    max_len, max_len_a = 50, 1.1\n",
    "    args.n_epochs = 55\n",
    "    args.batch_size = 48\n",
    "    args.lr = 4e-5\n",
    "    seed = 4373\n",
    "elif 're' in dataset_name:\n",
    "    max_len, max_len_a = 10, 1.6\n",
    "    args.num_beams = 4\n",
    "    args.lr = 2e-5\n",
    "    args.batch_size = 20\n",
    "    args.n_epochs = 100\n",
    "    seed = 1688\n",
    "    eval_start_epoch=1\n",
    "    rel_type_start = 10\n",
    "elif dataset_name == 're_ace05':\n",
    "    max_len, max_len_a = 10, 1.6\n",
    "    args.num_beams = 4\n",
    "    args.lr = 2e-5\n",
    "    args.batch_size = 80\n",
    "    args.n_epochs = 100\n",
    "    seed = 1571\n",
    "    eval_start_epoch=1\n",
    "    rel_type_start = 9\n",
    "elif dataset_name == 'en_ace05':  # three runs: 85.39/84.54/84.75\n",
    "    max_len, max_len_a = 50, 0.7\n",
    "    args.lr = 3e-5\n",
    "    args.batch_size = 12\n",
    "    args.num_beams = 4\n",
    "    args.warmup_ratio = 0.1\n",
    "\n",
    "set_seed(seed)\n",
    "# with open(\"/disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/loss_log/D.json\",\"r\") as f:\n",
    "#     b=f.readlines()\n",
    "# with open(\"/disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/loss_log/E.json\",\"r\") as f:\n",
    "#     c=f.readlines()\n",
    "# for x,y in zip(b,c):\n",
    "#     assert x==y,print(x,y)\n",
    "# exit()\n",
    "\n",
    "save_model = args.save_model\n",
    "del args.save_model\n",
    "lr = args.lr\n",
    "n_epochs = args.n_epochs\n",
    "batch_size = args.batch_size\n",
    "num_beams = args.num_beams\n",
    "\n",
    "length_penalty = args.length_penalty\n",
    "if isinstance(args.decoder_type, str) and args.decoder_type.lower() == 'none':\n",
    "    args.decoder_type = None\n",
    "decoder_type = args.decoder_type\n",
    "target_type = args.target_type\n",
    "bart_name = args.bart_name\n",
    "schedule = args.schedule\n",
    "use_encoder_mlp = args.use_encoder_mlp\n",
    "\n",
    "fitlog.add_hyper(args)\n",
    "\n",
    "#######hyper\n",
    "#######hyper\n",
    "\n",
    "demo = False\n",
    "if demo:\n",
    "    cache_fn = f\"caches/data_{bart_name}_{dataset_name}_{target_type}_demo.pt\"\n",
    "else:\n",
    "    cache_fn = f\"caches/data_{bart_name}_{dataset_name}_{target_type}.pt\"\n",
    "\n",
    "@cache_results(cache_fn, _refresh=False)\n",
    "def get_data():\n",
    "    if 're' in dataset_name:\n",
    "        pipe = Bart_RE_NER_Pipe(tokenizer=bart_name, dataset_name=dataset_name, target_type=target_type, no_ent_type=False)\n",
    "\n",
    "    if dataset_name == 'conll2003':\n",
    "        paths = {'test': \"./data/conll2003/test.txt\",\n",
    "                 'train': \"./data/conll2003/train.txt\",\n",
    "                 'dev': \"./data/conll2003/dev.txt\"}\n",
    "        data_bundle = pipe.process_from_file(paths, demo=demo)\n",
    "    elif dataset_name == 'en-ontonotes':\n",
    "        paths = './data/en-ontonotes/english'\n",
    "        data_bundle = pipe.process_from_file(paths)\n",
    "    else:\n",
    "        print(f'./data/{dataset_name}')\n",
    "        data_bundle = pipe.process_from_file(f'./data/{dataset_name}', demo=demo)\n",
    "    return pipe, data_bundle, pipe.tokenizer, pipe.mapping2id\n",
    "print(f'max_len_a:{max_len_a}, max_len:{max_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read cache from caches/data_/disk1/wxl/Desktop/DeepKE/example/ner/huggingface/bart-large_re_ner_ace05_word.pt.\n"
     ]
    }
   ],
   "source": [
    "pipe, data_bundle, tokenizer, mapping2id = get_data()\n",
    "ds = data_bundle.get_dataset(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_bundle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata_bundle\u001b[49m\u001b[38;5;241m.\u001b[39mget_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     tgt_seq_len \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgt_seq_len\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m     src_seq_len \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc_seq_len\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_bundle' is not defined"
     ]
    }
   ],
   "source": [
    "for i in data_bundle.get_dataset(\"train\"):\n",
    "    tgt_seq_len = i[\"tgt_seq_len\"]\n",
    "    src_seq_len = i[\"src_seq_len\"]\n",
    "    assert tgt_seq_len < 10 + 1.3*src_seq_len, f\"{tgt_seq_len},{src_seq_len},{i}\"\n",
    "for i in data_bundle.get_dataset(\"dev\"):\n",
    "    tgt_seq_len = i[\"tgt_seq_len\"]\n",
    "    src_seq_len = i[\"src_seq_len\"]\n",
    "    assert tgt_seq_len < 10 + 1.3*src_seq_len\n",
    "for i in data_bundle.get_dataset(\"test\"):\n",
    "    tgt_seq_len = i[\"tgt_seq_len\"]\n",
    "    src_seq_len = i[\"src_seq_len\"]\n",
    "    assert tgt_seq_len < 10 + 1.2*src_seq_len, f\"{tgt_seq_len},{src_seq_len},{10 + 1.3*src_seq_len},{i}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastNLP import DataSet,DataSetIter\n",
    "from fastNLP import SequentialSampler\n",
    "sampler = SequentialSampler()\n",
    "ds =  data_bundle.get_dataset(\"test\")\n",
    "batch = DataSetIter(batch_size=80, dataset=ds, sampler=sampler)\n",
    "batch2 = DataSetIter(batch_size=2, dataset=ds, sampler=sampler)\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 20,\n",
       " 6,\n",
       " 19,\n",
       " 5,\n",
       " 10,\n",
       " 21,\n",
       " 22,\n",
       " 6,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 5,\n",
       " 10,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 5,\n",
       " 35,\n",
       " 36,\n",
       " 5,\n",
       " 15,\n",
       " 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[6][\"re_tgt_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "metric类型: [RE]  rel_type_start: 9!\n",
      "\n",
      "正确预测个数： 694  错误预测个数： 364  未被预测的正确实体个数： 457\n",
      "{'f': 62.83, 'rec': 60.3, 'pre': 65.60000000000001, 'em': 0.78}\n",
      "0   1151   1058\n",
      "3453\n"
     ]
    }
   ],
   "source": [
    "from model.utils import get_span_from_pred, get_RE_from_pred,get_ent_tgt_tokens\n",
    "from itertools import chain\n",
    "max_type_id = len(pipe.mapping2targetid) + 2\n",
    "label_ids = list(mapping2id.values())\n",
    "if 're' in dataset_name:\n",
    "    metric = Seq2SeqREMetric(1, num_labels=len(label_ids), rel_type_start=rel_type_start, target_type=target_type)\n",
    "else:\n",
    "    metric = Seq2SeqSpanMetric(1, num_labels=len(label_ids), target_type=target_type)\n",
    "model2 = torch.load(\"/disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/save_models/re_ace05_1688_1734576024.9018843/best_SequenceGeneratorModel_f_2024-12-19-10-40-29-474678\").to('cuda')\n",
    "model2.eval()\n",
    "max_type_id = len(pipe.mapping2targetid) + 2\n",
    "pred_num = 0\n",
    "all_ent_num = 0\n",
    "false_num = 0\n",
    "true_num = 0\n",
    "false_pred_num = 0\n",
    "false_list = []\n",
    "true_list = [] \n",
    "false_pred_list = []\n",
    "for id,i in enumerate(batch):\n",
    "    #print(id)\n",
    "    src_tokens=i[0][\"src_tokens\"]\n",
    "    src_seq_len=i[0][\"src_seq_len\"]\n",
    "    first=i[0][\"first\"]\n",
    "    tgt_tokens = i[1][\"tgt_tokens\"].to('cuda')\n",
    "    pred = model2.predict(src_tokens.to('cuda'), src_seq_len.to('cuda'), first.to('cuda'))['pred']\n",
    "    pred_spans = [get_RE_from_pred(pred[id], max_type_id, 9) for id in range(pred.shape[0])]\n",
    "    \n",
    "    pred_spans = [set([str(y) for y in pred_spans[x]]) for x in range(pred.shape[0])]\n",
    "\n",
    "\n",
    "    #target_spans1 = [set([str(list(i[1][\"target_span\"][idxx][idx*3]) + list(i[1][\"target_span\"][idxx][idx*3+1]) + list(i[1][\"target_span\"][idxx][idx*3+2]) ) for idx in range(len(i[1][\"target_span\"][idxx]))]) for idxx in range(pred.shape[0])]\n",
    "    \n",
    "    target_spans = []\n",
    "    for idx_1 in range(pred.shape[0]):\n",
    "        one_batch_tgt = i[1][\"target_span\"][idx_1]\n",
    "        str_list = []\n",
    "        for idx_2 in (range(len(one_batch_tgt) // 3)):\n",
    "            rel_tgt = list(one_batch_tgt[idx_2*3]) + list(one_batch_tgt[idx_2*3+1]) +list(one_batch_tgt[idx_2*3+2])\n",
    "            rel_tgt.sort()\n",
    "            rel_tgt_str = str(rel_tgt)\n",
    "            str_list.append(rel_tgt_str)\n",
    "        target_spans.append(set(str_list))\n",
    "    false_spans = [target_spans[id] - pred_spans[id] for id in range(pred.shape[0])] # 没预测出来的span\n",
    "    # print(false_spans)\n",
    "    true_spans = [target_spans[id] & pred_spans[id] for id in range(pred.shape[0])] # 预测出来的span\n",
    "    # x = [list(ss) for ss in pred_spans]\n",
    "    # y = [list(ss) for ss in target_spans]\n",
    "    # for xx in x:\n",
    "    #     xx.sort()\n",
    "    # for yy in y:\n",
    "    #     yy.sort()\n",
    "    # print(\"pred_spans: \",x, \"\\ntarget_spans\",y,\"\\n\")\n",
    "    # print(\"pred_spans: \",pred_spans, \"\\ntarget_spans\",target_spans,\"\\n\")\n",
    "    # if id > 10:\n",
    "    #     break\n",
    "    false_pred_spans = [pred_spans[id] - target_spans[id] for id in range(pred.shape[0])]\n",
    "    # print(\"false_pred_spans: \",false_pred_spans, \"\\nfalse_spans\",false_spans,\"\\n\")\n",
    "    all_ent_num += sum(len(i[1][\"target_span\"][id]) for id in range(pred.shape[0]))\n",
    "    false_num += sum([len(fs) for fs in false_spans])\n",
    "    true_num += sum([len(ts) for ts in true_spans])\n",
    "    false_pred_num += sum(len(fps) for fps in false_pred_spans)\n",
    "    false_list += false_spans\n",
    "    true_list += true_spans\n",
    "    false_pred_list += false_pred_spans\n",
    "    res = metric.evaluate(i[1][\"target_span\"], pred, tgt_tokens)\n",
    "    # print(\"pred: \",pred, \"\\ntarget: \",tgt_tokens,\"\\n\")\n",
    "print(metric.get_metric())\n",
    "print(true_num, \" \", false_num, \" \", false_pred_num)\n",
    "print(all_ent_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47114, 46317, 46797]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['relation','entity','input'])\n",
    "#print(tokenizer.convert_ids_to_tokens([2]))\n",
    "# # print(\"=================\")\n",
    "\n",
    "# label_ids = list(mapping2id.values())\n",
    "# metric = Seq2SeqSpanMetric(1, num_labels=len(label_ids), target_type=target_type)\n",
    "# model2.eval()\n",
    "# max_type_id = len(pipe.mapping2targetid) + 2\n",
    "# pred_num = 0\n",
    "# all_ent_num = 0\n",
    "# false_num = 0\n",
    "# true_num = 0\n",
    "# false_pred_num = 0\n",
    "# false_list = []\n",
    "# true_list = [] \n",
    "# false_pred_list = []\n",
    "# for id,i in enumerate(batch2):\n",
    "#     src_tokens=i[0][\"src_tokens\"]\n",
    "#     src_seq_len=i[0][\"src_seq_len\"]\n",
    "#     first=i[0][\"first\"]\n",
    "#     tgt_tokens = i[1][\"tgt_tokens\"].to('cuda')\n",
    "#     pred = model2.predict(src_tokens.to('cuda'), src_seq_len.to('cuda'), first.to('cuda'))['pred']\n",
    "#     print(pred)\n",
    "#     pred_spans = [get_span_from_pred(pred[id], max_type_id) for id in range(pred.shape[0])]\n",
    "#     pred_spans = [set([str(y) for y in pred_spans[x]]) for x in range(pred.shape[0])]\n",
    "\n",
    "#     target_spans = [set([str(list(span)) for span in i[1][\"target_span\"][id]]) for id in range(pred.shape[0])]\n",
    "    \n",
    "#     false_spans = [target_spans[id] - pred_spans[id] for id in range(pred.shape[0])] # 没预测出来的span\n",
    "#     #print(false_spans)\n",
    "#     true_spans = [target_spans[id] & pred_spans[id] for id in range(pred.shape[0])] # 没预测出来的span\n",
    "#     x = [list(ss) for ss in pred_spans]\n",
    "#     y = [list(ss) for ss in target_spans]\n",
    "#     for xx in x:\n",
    "#         xx.sort()\n",
    "#     for yy in y:\n",
    "#         yy.sort()\n",
    "#     print(\"pred_spans: \",pred_spans, \"\\ntarget_spans\",target_spans,\"\\n\")\n",
    "#     if id > 1:\n",
    "#         break\n",
    "#     false_pred_spans = [pred_spans[id] - target_spans[id] for id in range(pred.shape[0])]\n",
    "#     pred_num += sum([len(x[i]) for i in range(pred.shape[0])])\n",
    "#     all_ent_num += sum(len(i[1][\"target_span\"][id]) for id in range(pred.shape[0]))\n",
    "#     false_num += sum([len(fs) for fs in false_spans])\n",
    "#     true_num += sum([len(ts) for ts in true_spans])\n",
    "#     false_pred_num += sum(len(fps) for fps in false_pred_spans)\n",
    "#     false_list += false_spans\n",
    "#     true_list += true_spans\n",
    "#     false_pred_list += false_pred_spans\n",
    "#     res = metric.evaluate(i[1][\"target_span\"], pred, tgt_tokens)\n",
    "#     #print(\"pred: \",pred, \"\\ntarget: \",tgt_tokens,\"\\n\")\n",
    "# print(metric.get_metric())\n",
    "# print(true_num, \" \", false_num, \" \", false_pred_num)\n",
    "# print(all_ent_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
