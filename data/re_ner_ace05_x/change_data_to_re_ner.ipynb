{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "def cat_with(y):\n",
    "    z = []\n",
    "    for i in y:\n",
    "        z.append(' '.join(i)) # 把sentence从list -> str\n",
    "    z2 = []\n",
    "    for i in y:\n",
    "        z2 += i\n",
    "    # 返回一个sentence的str列表和全部拼接的完整sentences（用于校验）\n",
    "    return z, z2\n",
    "def relations_change(offsets, y, rel_type_list, all_sentences, sentences, ner_dict_list):\n",
    "    z = []\n",
    "    for i, cur_sentence, offset, ner_dict in zip(y, sentences, offsets, ner_dict_list):\n",
    "        # [r1, r2...]\n",
    "        zz = [] # 界定不同sentence的relations的边界\n",
    "        for j in i:\n",
    "            # r1: [s1, e1, s2, e2, rel_type]\n",
    "            head_ent_type = ner_dict[str(j[0:2])].lower()\n",
    "            tail_ent_type = ner_dict[str(j[2:4])].lower()\n",
    "            jj = [se_value - offset for se_value in j[:-1]] # 将原始的位置减去偏移量得到以当前sentence为起点的坐标\n",
    "\n",
    "            # 校验对应内容\n",
    "            assert cur_sentence[jj[0]:jj[1]+1] == all_sentences[j[0]:j[1]+1] and cur_sentence[jj[2]:jj[3]+1] == all_sentences[j[2]:j[3]+1],f'{cur_sentence[jj[0]:jj[1]+1]} == {all_sentences[j[0]:j[1]+1]} and {cur_sentence[jj[2]:jj[3]+1]} == {all_sentences[j[2]:j[3]+1]}'\n",
    "\n",
    "            jj = [str(jjj) for jjj in jj]\n",
    "            two_ent_se = ','.join(jj)\n",
    "            head_ent_se = ','.join(jj[0:2])\n",
    "            tail_ent_se = ','.join(jj[2:4])\n",
    "            rel_type = j[-1].lower()\n",
    "\n",
    "            rel_type_list.add(rel_type)\n",
    "            rel_type_list.add(head_ent_type)\n",
    "            rel_type_list.add(tail_ent_type)\n",
    "\n",
    "            head_ent = head_ent_se + \" \" + head_ent_type\n",
    "            tail_ent = tail_ent_se + \" \" + tail_ent_type\n",
    "            rel = \" \" + rel_type\n",
    "            zz.append(head_ent)\n",
    "            zz.append(tail_ent)\n",
    "            zz.append(rel)\n",
    "        z.append(zz)\n",
    "\n",
    "    # 返回一个长度和sentence个数一致的relations列表：[[r1,r2],[r3],[r5,r6,r7]...]\n",
    "    return z, rel_type_list\n",
    "def change(in_file, out_file, rel_type_list):\n",
    "    out_data = []\n",
    "    with open(in_file,\"r\") as f:\n",
    "       in_data= f.readlines()\n",
    "    for idata in in_data:\n",
    "        idata = json.loads(idata)\n",
    "\n",
    "        # sentences\n",
    "        sentences = idata[\"sentences\"]\n",
    "        offsets = np.cumsum([0] + [len(sentence) for sentence in sentences[:-1]])\n",
    "        sentences, all_sentences = cat_with(sentences)\n",
    "        # relations to discontinuous entity\n",
    "        relations = idata[\"relations\"]\n",
    "\n",
    "        ner = idata[\"ner\"]\n",
    "        ner_dict_list = []\n",
    "        for ner_i in ner:\n",
    "            ner_dict = {}\n",
    "            for ner_ii in ner_i:\n",
    "                if ner_ii == []:\n",
    "                    continue\n",
    "                ner_dict[str(ner_ii[:2])] = ner_ii[2]\n",
    "            ner_dict_list.append(ner_dict)\n",
    "\n",
    "        relations, rel_type_list = relations_change(offsets, relations, rel_type_list, all_sentences, idata[\"sentences\"], ner_dict_list)\n",
    "\n",
    "        # 保证sentences、relations个数一致\n",
    "        assert len(sentences) == len(relations) == len(idata[\"relations\"])\n",
    "        for r, ro in zip(relations, idata[\"relations\"]):\n",
    "            assert len(r) == 3*len(ro)\n",
    "        \n",
    "        for sentence, relation, ner_i, offset in zip(sentences, relations, ner, offsets):\n",
    "            out_data.append(sentence)\n",
    "            ner_i_str = []\n",
    "            for ner_ii in ner_i:\n",
    "                ner_ii[0:2] -= offset\n",
    "                ner_ii = [str(x) for x in ner_ii]\n",
    "                x = ','.join(ner_ii[0:2]) + \" \" + ner_ii[2].lower()\n",
    "                ner_i_str.append(x)\n",
    "            out_data.append('|'.join(ner_i_str))\n",
    "            out_data.append('|'.join(relation))\n",
    "            out_data.append(\"\")\n",
    "    with open(out_file,\"w\") as f:\n",
    "       for i in out_data:\n",
    "           f.write(i+\"\\n\")\n",
    "    return rel_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{'veh', 'part-whole', 'per-soc', 'gen-aff', 'org-aff', 'org', 'loc', 'art', 'wea', 'fac', 'gpe', 'phys', 'per'}\n",
      "{'veh', 'part-whole', 'per-soc', 'gen-aff', 'org-aff', 'org', 'loc', 'art', 'wea', 'fac', 'gpe', 'phys', 'per'}\n",
      "{'veh', 'part-whole', 'per-soc', 'gen-aff', 'org-aff', 'org', 'loc', 'art', 'wea', 'fac', 'gpe', 'phys', 'per'}\n"
     ]
    }
   ],
   "source": [
    "rel_type_list = set()\n",
    "print(rel_type_list)\n",
    "rel_type_list = change(\"/disk1/wxl/Desktop/DeepKE/example/ner/BiSPN/data/ace2005/train.json\",\"//disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/data/re_ner_ace05/train.txt\", rel_type_list)\n",
    "print(rel_type_list)\n",
    "rel_type_list = change(\"/disk1/wxl/Desktop/DeepKE/example/ner/BiSPN/data/ace2005/dev.json\",\"/disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/data/re_ner_ace05/dev.txt\", rel_type_list)\n",
    "print(rel_type_list)\n",
    "rel_type_list = change(\"/disk1/wxl/Desktop/DeepKE/example/ner/BiSPN/data/ace2005/test.json\",\"/disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/data/re_ner_ace05/test.txt\",rel_type_list)\n",
    "print(rel_type_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
